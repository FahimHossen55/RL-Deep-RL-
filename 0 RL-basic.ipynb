{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Elements:** \n- **Agent :**  The entity to learns to make decesions in the Environment\n- **Environment:** The external world that the agent interects with\n- **State** : Position in envionment\n- **Action**: The decesion made by the agent in responce to the environment\n- **Reward** :  The feedback received by the agent from the environment based on its action\n- **Policy** : The Strategy used by the agent from the environment\n- **Value** :  Goodness of future reward\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"##  Way to implement : \n- ### Model-free RL \n- ### Model based RL \n- ### Deep reinforcement learning \n- ###  Actor-Critic Methods \n- ### Meta RL ( Ex, MAML model Agnostic MMeta learning ) \n","metadata":{}},{"cell_type":"markdown","source":"## STATE VECTOR ","metadata":{}},{"cell_type":"markdown","source":"in RL , A state vector is a numerical representaton of the current state of the environment that an agent uses to make decesions about what action to take \n","metadata":{}},{"cell_type":"markdown","source":"## Policy \nA policy is a mapping between states of the environment and the actions to be taken in those states. it specifies what action the agent should take in a given state to maximize its expected cumulative reward over time \n- A dereministic policy \n- A probabilistic policy\n","metadata":{}},{"cell_type":"markdown","source":"## Exploration & Exploitation \n- ### Exploration :\n- Exploration  is the new techinique of trying out new actions to gain information about the environment . it allows the agent to discover new states and learn How to behave in those states However excessive exploration may prevent the agent from exploitating its current knowledge of the environment\n- ### Exploitation :\n-  Exploitation is the process of taking actions that agent believes will maximize its expected cumulative reward based on its current knowledge of the environment. it allows the agent to maximize its reward in short term.\n-   To find optimal policy. the agent must balane exploration and exploitation. it must explore enough to discover new states and actions.\n","metadata":{}},{"cell_type":"markdown","source":"##  Exploration - Exploitation TRADE OFF \n\n- Epsilon greedy: This is a strategy that balance exploration and exploitation by choosing the best action with high probability and choosing a random action with low probability\n- Boltzman Exploitation: Boltzman exploitation is a strategy that balance exploration and exploitaion by assigning  probabilistics to each action based on its expected reward and choosing actions probabilistically based on these probabilistics\n  ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}