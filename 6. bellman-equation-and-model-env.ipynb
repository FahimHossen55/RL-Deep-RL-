{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **BellMan Equation**   \n## The bellman Equation is fundamental Concept in reinforcement learning that expresses the relation between the value of a state and the values of its successor state. <br>  \n \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# **Model of Environment**  \n## There are Several Algorithm  for reinforcement learning, The model is presented \"\"  <br> \n \nWe have two categories in these algorithms :  \n- **Model based :** In model based algorithms, we require a model that learns from  state transitions and current actions. How ever , after a certain number of steps. it becomes impractical as the model would need to store all the state and action data in memory.  \n- **model free:** on the other hand, in model free algorithms , there is no need to be concerned about a large model taking up space. This alogorithm wotks based on trail and error , eliminating the need to store states and actions.    \n ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}